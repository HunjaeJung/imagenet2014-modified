@article{ILSVRC15,
    Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    Title = {{ImageNet Large Scale Visual Recognition Challenge}},
    Year = {2015},
    journal   = {International Journal of Computer Vision (IJCV)},
    doi = {10.1007/s11263-015-0816-y}
}

@incollection{AlexNet,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Geoffrey E. Hinton},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C.J.C. Burges and L. Bottou and K.Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@article{GoogleNet,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.4842},
  timestamp = {Wed, 01 Oct 2014 15:00:05 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SzegedyLJSRAEVR14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@article{ZFnet,
  author    = {Matthew D. Zeiler and
               Rob Fergus},
  title     = {Visualizing and Understanding Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1311.2901},
  year      = {2013},
  url       = {http://arxiv.org/abs/1311.2901},
  timestamp = {Tue, 03 Dec 2013 15:04:22 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ZeilerF13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{VGGNet,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@INCOLLECTION{LeNet,
     author = {{LeCun}, Yann and Bottou, {L{\'{e}}on} and Bengio, Yoshua and Haffner, Patrick},
     editor = {Haykin, S. and Kosko, B.},
      title = {Gradient-Based Learning Applied to Document Recognition},
  booktitle = {Intelligent Signal Processing},
       year = {2001},
      pages = {306--351},
  publisher = {IEEE Press},
        url = {http://www.iro.umontreal.ca/~lisa/pointeurs/lecun-01a.pdf},
   abstract = {Multilayer Neural Networks trained with a backprppagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques.
Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to monimize an overall peformance measure.
Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks.
A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with a global training technique to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day.},
topics={PriorKnowledge,Speech},cat={B},
}


book{Xbook,
    author    = "",
    title     = "",
    publisher = "",
    %volume   = "",
    %number   = "",
    %series   = "",
    %address  = "",
    %edition  = "",
    year      = "XXXX",
    %month    = "",
    %note     = "",
}

booklet{Xbooklet,
    %author   = "",
    title     = "",
    %howpublished   = "",
    %address  = "",
    year      = "XXXX",
    %month    = "",
    %note     = "",
}

conference{Xconference,
    author    = "",
    title     = "",
    booktitle = "",
    %editor   = "",
    %volume   = "",
    %number   = "",
    %series   = "",
    %pages    = "",
    %address  = "",
    year      = "XXXX",
    %month    = "",
    %publisher= "",
    %note     = "",
}

mastersthesis{Xthesis,
    author    = "",
    title     = "",
    school    = "",
    %type     = "diploma thesis",
    %address  = "",
    year      = "XXXX",
    %month    = "",
    %note     = "",
}

misc{Xmisc,
    %author    = "",
    %title     = "",
    %howpublished = "",
    %year     = "XXXX",
    %month    = "",
    %note     = "",
}
